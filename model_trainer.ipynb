{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jupyter Notebook to train a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "from tf_explain.callbacks.grad_cam import GradCAMCallback\n",
    "\n",
    "# use random seed to reproduce results\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### lists possible devices (CPU, GPU), used to check if GPU is recognized/exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'),\n PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.get_visible_devices()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### used to save a trained model as a json file and its weights as a h5 file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def save_model(model, model_name):\n",
    "    my_model = model.to_json()\n",
    "    with open(f'./saved_models/{model_name}.json', \"w\") as file:\n",
    "        file.write(my_model)\n",
    "    # serialize weights to HDF5\n",
    "    model.save_weights(f'./saved_models/{model_name}_weights.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### used to build the base model using predefined architectures\n",
    "currently: vgg16, xception, resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def build_base_model(architecture, weights):\n",
    "    input = tf.keras.Input(shape=(224, 224, 3))\n",
    "    if architecture == 'vgg16':\n",
    "        return tf.keras.applications.vgg16.VGG16(weights=weights, include_top=False, input_tensor=input)\n",
    "    if architecture == 'xception':\n",
    "        return tf.keras.applications.xception.Xception(weights=weights, include_top=False, input_tensor=input)\n",
    "    if architecture == 'resnet':\n",
    "        return tf.keras.applications.resnet.ResNet50(weights=weights, include_top=False, input_tensor=input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### gets base model as input and builds a new top layer and returns the model with custom top layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def build_model(base_model):\n",
    "    flat = keras.layers.Flatten(name='flatten')(base_model.output)\n",
    "    dense_1 = keras.layers.Dense(2800)(flat)\n",
    "    dropout = keras.layers.Dropout(0.25)(dense_1)\n",
    "    batch = keras.layers.BatchNormalization()(dropout)\n",
    "    output = keras.layers.Dense(1, activation='sigmoid')(batch)\n",
    "    return tf.keras.Model(base_model.input, output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### gets a model as input and returns a model compiled with the adam optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def compile_model(model, alpha, beta1, beta2, metrics):\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=alpha, beta_1=beta1, beta_2=beta2)\n",
    "    model.compile(loss=\"binary_crossentropy\", optimizer=optimizer, metrics=metrics)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### gets a model as input and trains it on the data-set with the defined callbacks and epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def train_model(model, train_set, validation_set, epochs, callback):\n",
    "    return model.fit(train_set,\n",
    "                     validation_data=validation_set,\n",
    "                     epochs=epochs,\n",
    "                     callbacks=callback)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### gets a model as input and changes its layers trainable attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def set_layers_trainable(trainable, input_model):\n",
    "    for layer in input_model.layers:\n",
    "        layer.trainable = trainable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### preprocessing of the images applied when loading image data set from disk with tensorflows flow_from_directory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "image_gen = keras.preprocessing.image.ImageDataGenerator(rotation_range=20,  # rotate the image 20 degrees\n",
    "                                                         width_shift_range=0.2,\n",
    "                                                         height_shift_range=0.2,\n",
    "                                                         rescale=1 / 255,  # Rescale the image by normalzing it.\n",
    "                                                         shear_range=0.15,\n",
    "                                                         # Shear means cutting away part of the image (max 20%)\n",
    "                                                         zoom_range=0.15,  # Zoom in by 15% max\n",
    "                                                         horizontal_flip=True,  # Allow horizontal flipping\n",
    "                                                         fill_mode='nearest'\n",
    "                                                         # Fill in missing pixels with the nearest filled value\n",
    "                                                         )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### path to the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_data_path = './data/data_full/train'  #local notebook\n",
    "test_data_path = './data/data_full/test'  #local notebook\n",
    "validation_data_path = './data/data_full/val'  #local notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### generate training set by loading the images from their directories with flow_from_directory\n",
    "### important: the folder structure has to match! i.e {train} -> {ok,def}\n",
    "### at the \"same time\" the data augmentation is applied on the images through the ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 48271 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 12\n",
    "train_image_gen = image_gen.flow_from_directory(train_data_path,\n",
    "                                                target_size=(224, 224),\n",
    "                                                batch_size=batch_size,\n",
    "                                                class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6033 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "valid_image_gen = image_gen.flow_from_directory(validation_data_path,\n",
    "                                                target_size=(224, 224),\n",
    "                                                batch_size=batch_size,\n",
    "                                                class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6036 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "test_image_gen = image_gen.flow_from_directory(test_data_path,\n",
    "                                               target_size=(224, 224),\n",
    "                                               batch_size=batch_size,\n",
    "                                               class_mode='binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training of the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre Training\n",
    "* build base model with vgg16 architecture and pretrained with imagenet weights\n",
    "* add custom layers on base model\n",
    "* compile model with adam optimizer\n",
    "* freeze layers of pretrained vgg16 base model to not destroy imagenet weights\n",
    "* train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-15 14:37:15.720107: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-12-15 14:37:15.720502: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-15 14:37:15.720673: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: NVIDIA GeForce GTX 1080 computeCapability: 6.1\n",
      "coreClock: 1.8225GHz coreCount: 20 deviceMemorySize: 7.93GiB deviceMemoryBandwidth: 298.32GiB/s\n",
      "2021-12-15 14:37:15.720710: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2021-12-15 14:37:15.720764: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2021-12-15 14:37:15.720788: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2021-12-15 14:37:15.720806: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2021-12-15 14:37:15.720823: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2021-12-15 14:37:15.720842: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2021-12-15 14:37:15.720860: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2021-12-15 14:37:15.720878: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2021-12-15 14:37:15.720966: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-15 14:37:15.721150: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-15 14:37:15.721268: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2021-12-15 14:37:15.721761: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2021-12-15 14:37:16.696499: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2021-12-15 14:37:16.696522: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 \n",
      "2021-12-15 14:37:16.696527: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N \n",
      "2021-12-15 14:37:16.697114: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-15 14:37:16.697290: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-15 14:37:16.697411: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-15 14:37:16.697511: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 5906 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce GTX 1080, pci bus id: 0000:01:00.0, compute capability: 6.1)\n",
      "2021-12-15 14:37:16.699032: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2021-12-15 14:37:17.295641: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2021-12-15 14:37:17.315652: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 3999980000 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-15 14:37:18.514117: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2021-12-15 14:37:18.822378: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2021-12-15 14:37:19.752241: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256\n",
      "2021-12-15 14:37:19.775332: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: \n",
      "Relying on driver to perform ptx compilation. \n",
      "Modify $PATH to customize ptxas location.\n",
      "This message will be only logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4023/4023 [==============================] - 739s 181ms/step - loss: 0.3307 - accuracy: 0.8598 - recall: 0.7485 - precision: 0.5981 - auc: 0.8971 - val_loss: 0.3369 - val_accuracy: 0.8850 - val_recall: 0.3053 - val_precision: 1.0000 - val_auc: 0.9604\n",
      "Epoch 2/5\n",
      "4023/4023 [==============================] - 754s 188ms/step - loss: 0.0840 - accuracy: 0.9703 - recall: 0.8938 - precision: 0.9253 - auc: 0.9897 - val_loss: 0.0278 - val_accuracy: 0.9874 - val_recall: 0.9279 - val_precision: 0.9957 - val_auc: 0.9997\n",
      "Epoch 3/5\n",
      "4023/4023 [==============================] - 737s 183ms/step - loss: 0.0565 - accuracy: 0.9806 - recall: 0.9282 - precision: 0.9524 - auc: 0.9934 - val_loss: 0.0262 - val_accuracy: 0.9924 - val_recall: 0.9910 - val_precision: 0.9640 - val_auc: 0.9997\n",
      "Epoch 4/5\n",
      "4023/4023 [==============================] - 754s 187ms/step - loss: 0.0303 - accuracy: 0.9899 - recall: 0.9639 - precision: 0.9747 - auc: 0.9980 - val_loss: 0.2309 - val_accuracy: 0.9130 - val_recall: 1.0000 - val_precision: 0.6555 - val_auc: 0.9987\n",
      "Epoch 5/5\n",
      "4023/4023 [==============================] - 749s 186ms/step - loss: 0.0245 - accuracy: 0.9912 - recall: 0.9682 - precision: 0.9796 - auc: 0.9987 - val_loss: 0.0126 - val_accuracy: 0.9955 - val_recall: 0.9740 - val_precision: 0.9990 - val_auc: 0.9999\n"
     ]
    }
   ],
   "source": [
    "vgg16 = build_base_model('vgg16', 'imagenet')\n",
    "model = build_model(vgg16)\n",
    "model = compile_model(model, 8.837e-05, 0.9, 0.999, ['accuracy', 'Recall', 'Precision', 'AUC'])\n",
    "set_layers_trainable(False, vgg16)\n",
    "history = train_model(model, train_image_gen, valid_image_gen, 5, [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "save_model(model, 'vgg16_only_pretrained_tuned_parameters')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full Training\n",
    "* un freeze layers of pretrained vgg16 base model\n",
    "* define callbacks\n",
    "    * tensorboard callback to generate reports which can be viewed in tensorboard\n",
    "    * early stopping callback to stop training after monitored metric has not changed after, by the patience defined, epochs\n",
    "* compile model with adam optimizer\n",
    "* train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "set_layers_trainable(True, vgg16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-07 20:07:19.281741: I tensorflow/core/profiler/lib/profiler_session.cc:136] Profiler session initializing.\n",
      "2021-12-07 20:07:19.281774: I tensorflow/core/profiler/lib/profiler_session.cc:155] Profiler session started.\n",
      "2021-12-07 20:07:19.281993: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1365] Profiler found 1 GPUs\n",
      "2021-12-07 20:07:19.290065: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcupti.so.10.1\n",
      "2021-12-07 20:07:19.391355: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1415] function cupti_interface_->Subscribe( &subscriber_, (CUpti_CallbackFunc)ApiCallback, this)failed with error CUPTI_ERROR_INSUFFICIENT_PRIVILEGES\n",
      "2021-12-07 20:07:19.392395: I tensorflow/core/profiler/lib/profiler_session.cc:172] Profiler session tear down.\n"
     ]
    }
   ],
   "source": [
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=\"./logs\", histogram_freq=5, write_graph=True, write_images=True)\n",
    "custom_early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss', patience=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "  1/800 [..............................] - ETA: 47:38 - loss: 3.3124e-04 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - auc: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-07 20:07:25.043807: I tensorflow/core/profiler/lib/profiler_session.cc:136] Profiler session initializing.\n",
      "2021-12-07 20:07:25.043830: I tensorflow/core/profiler/lib/profiler_session.cc:155] Profiler session started.\n",
      "2021-12-07 20:07:25.044275: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1415] function cupti_interface_->Subscribe( &subscriber_, (CUpti_CallbackFunc)ApiCallback, this)failed with error CUPTI_ERROR_INSUFFICIENT_PRIVILEGES\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  2/800 [..............................] - ETA: 5:07 - loss: 0.0011 - accuracy: 1.0000 - recall: 1.0000 - precision: 1.0000 - auc: 1.0000     "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-07 20:07:25.307700: I tensorflow/core/profiler/lib/profiler_session.cc:71] Profiler session collecting data.\n",
      "2021-12-07 20:07:25.318480: I tensorflow/core/profiler/internal/gpu/cupti_collector.cc:228]  GpuTracer has collected 0 callback api events and 0 activity events. \n",
      "2021-12-07 20:07:25.322665: I tensorflow/core/profiler/lib/profiler_session.cc:172] Profiler session tear down.\n",
      "2021-12-07 20:07:25.329030: I tensorflow/core/profiler/rpc/client/save_profile.cc:137] Creating directory: ./logs/train/plugins/profile/2021_12_07_20_07_25\n",
      "2021-12-07 20:07:25.330457: I tensorflow/core/profiler/rpc/client/save_profile.cc:143] Dumped gzipped tool data for trace.json.gz to ./logs/train/plugins/profile/2021_12_07_20_07_25/pop-os.trace.json.gz\n",
      "2021-12-07 20:07:25.362010: I tensorflow/core/profiler/rpc/client/save_profile.cc:137] Creating directory: ./logs/train/plugins/profile/2021_12_07_20_07_25\n",
      "2021-12-07 20:07:25.366774: I tensorflow/core/profiler/rpc/client/save_profile.cc:143] Dumped gzipped tool data for memory_profile.json.gz to ./logs/train/plugins/profile/2021_12_07_20_07_25/pop-os.memory_profile.json.gz\n",
      "2021-12-07 20:07:25.367735: I tensorflow/core/profiler/rpc/client/capture_profile.cc:251] Creating directory: ./logs/train/plugins/profile/2021_12_07_20_07_25Dumped tool data for xplane.pb to ./logs/train/plugins/profile/2021_12_07_20_07_25/pop-os.xplane.pb\n",
      "Dumped tool data for overview_page.pb to ./logs/train/plugins/profile/2021_12_07_20_07_25/pop-os.overview_page.pb\n",
      "Dumped tool data for input_pipeline.pb to ./logs/train/plugins/profile/2021_12_07_20_07_25/pop-os.input_pipeline.pb\n",
      "Dumped tool data for tensorflow_stats.pb to ./logs/train/plugins/profile/2021_12_07_20_07_25/pop-os.tensorflow_stats.pb\n",
      "Dumped tool data for kernel_stats.pb to ./logs/train/plugins/profile/2021_12_07_20_07_25/pop-os.kernel_stats.pb\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 199s 244ms/step - loss: 0.0358 - accuracy: 0.9899 - recall: 0.9880 - precision: 0.9919 - auc: 0.9979 - val_loss: 0.0393 - val_accuracy: 0.9880 - val_recall: 0.9900 - val_precision: 0.9860 - val_auc: 0.9977\n",
      "Epoch 2/100\n",
      "800/800 [==============================] - 194s 243ms/step - loss: 0.0353 - accuracy: 0.9904 - recall: 0.9912 - precision: 0.9896 - auc: 0.9982 - val_loss: 0.0273 - val_accuracy: 0.9940 - val_recall: 1.0000 - val_precision: 0.9881 - val_auc: 0.9989\n",
      "Epoch 3/100\n",
      "800/800 [==============================] - 195s 243ms/step - loss: 0.0481 - accuracy: 0.9873 - recall: 0.9888 - precision: 0.9859 - auc: 0.9972 - val_loss: 0.0890 - val_accuracy: 0.9810 - val_recall: 0.9619 - val_precision: 1.0000 - val_auc: 0.9959\n",
      "Epoch 4/100\n",
      "800/800 [==============================] - 195s 244ms/step - loss: 0.0164 - accuracy: 0.9933 - recall: 0.9942 - precision: 0.9926 - auc: 0.9997 - val_loss: 0.0294 - val_accuracy: 0.9910 - val_recall: 0.9920 - val_precision: 0.9900 - val_auc: 0.9996\n",
      "Epoch 5/100\n",
      "800/800 [==============================] - 195s 244ms/step - loss: 0.0194 - accuracy: 0.9957 - recall: 0.9955 - precision: 0.9960 - auc: 0.9994 - val_loss: 0.0104 - val_accuracy: 0.9970 - val_recall: 0.9940 - val_precision: 1.0000 - val_auc: 0.9999\n",
      "Epoch 6/100\n",
      "800/800 [==============================] - 196s 245ms/step - loss: 0.0253 - accuracy: 0.9953 - recall: 0.9988 - precision: 0.9918 - auc: 0.9981 - val_loss: 0.0083 - val_accuracy: 0.9980 - val_recall: 0.9980 - val_precision: 0.9980 - val_auc: 0.9999\n",
      "Epoch 7/100\n",
      "800/800 [==============================] - 196s 245ms/step - loss: 0.0160 - accuracy: 0.9955 - recall: 0.9959 - precision: 0.9952 - auc: 0.9997 - val_loss: 0.0044 - val_accuracy: 0.9990 - val_recall: 0.9980 - val_precision: 1.0000 - val_auc: 1.0000\n",
      "Epoch 8/100\n",
      "800/800 [==============================] - 196s 245ms/step - loss: 0.0154 - accuracy: 0.9965 - recall: 0.9977 - precision: 0.9952 - auc: 0.9992 - val_loss: 0.0545 - val_accuracy: 0.9880 - val_recall: 0.9760 - val_precision: 1.0000 - val_auc: 0.9969\n",
      "Epoch 9/100\n",
      "800/800 [==============================] - 197s 246ms/step - loss: 0.0260 - accuracy: 0.9944 - recall: 0.9926 - precision: 0.9959 - auc: 0.9991 - val_loss: 0.0253 - val_accuracy: 0.9910 - val_recall: 0.9820 - val_precision: 1.0000 - val_auc: 0.9990\n",
      "Epoch 10/100\n",
      "800/800 [==============================] - 200s 250ms/step - loss: 0.0189 - accuracy: 0.9970 - recall: 0.9980 - precision: 0.9961 - auc: 0.9992 - val_loss: 0.0128 - val_accuracy: 0.9930 - val_recall: 0.9940 - val_precision: 0.9920 - val_auc: 0.9999\n",
      "Epoch 11/100\n",
      "800/800 [==============================] - 201s 252ms/step - loss: 0.0053 - accuracy: 0.9985 - recall: 0.9984 - precision: 0.9985 - auc: 0.9999 - val_loss: 0.0049 - val_accuracy: 0.9990 - val_recall: 0.9980 - val_precision: 1.0000 - val_auc: 1.0000\n",
      "Epoch 12/100\n",
      "800/800 [==============================] - 203s 253ms/step - loss: 0.0108 - accuracy: 0.9971 - recall: 0.9974 - precision: 0.9968 - auc: 0.9998 - val_loss: 0.0054 - val_accuracy: 0.9980 - val_recall: 0.9960 - val_precision: 1.0000 - val_auc: 1.0000\n",
      "Epoch 13/100\n",
      "800/800 [==============================] - 207s 259ms/step - loss: 0.0128 - accuracy: 0.9960 - recall: 0.9964 - precision: 0.9956 - auc: 0.9994 - val_loss: 0.0036 - val_accuracy: 0.9990 - val_recall: 0.9980 - val_precision: 1.0000 - val_auc: 1.0000\n",
      "Epoch 14/100\n",
      "800/800 [==============================] - 207s 259ms/step - loss: 0.0165 - accuracy: 0.9973 - recall: 0.9977 - precision: 0.9969 - auc: 0.9992 - val_loss: 0.0502 - val_accuracy: 0.9850 - val_recall: 0.9699 - val_precision: 1.0000 - val_auc: 0.9964\n",
      "Epoch 15/100\n",
      "800/800 [==============================] - 207s 259ms/step - loss: 0.0121 - accuracy: 0.9957 - recall: 0.9948 - precision: 0.9967 - auc: 0.9998 - val_loss: 0.0077 - val_accuracy: 0.9970 - val_recall: 0.9940 - val_precision: 1.0000 - val_auc: 1.0000\n",
      "Epoch 16/100\n",
      "800/800 [==============================] - 209s 261ms/step - loss: 0.0106 - accuracy: 0.9979 - recall: 0.9983 - precision: 0.9974 - auc: 0.9995 - val_loss: 0.0048 - val_accuracy: 0.9990 - val_recall: 0.9980 - val_precision: 1.0000 - val_auc: 1.0000\n",
      "Epoch 17/100\n",
      "800/800 [==============================] - 208s 260ms/step - loss: 0.0126 - accuracy: 0.9963 - recall: 0.9948 - precision: 0.9979 - auc: 0.9995 - val_loss: 0.0075 - val_accuracy: 0.9960 - val_recall: 0.9960 - val_precision: 0.9960 - val_auc: 1.0000\n",
      "Epoch 18/100\n",
      "800/800 [==============================] - 208s 260ms/step - loss: 0.0039 - accuracy: 0.9988 - recall: 0.9986 - precision: 0.9989 - auc: 1.0000 - val_loss: 5.9473e-04 - val_accuracy: 1.0000 - val_recall: 1.0000 - val_precision: 1.0000 - val_auc: 1.0000\n",
      "Epoch 19/100\n",
      "800/800 [==============================] - 208s 260ms/step - loss: 0.0057 - accuracy: 0.9991 - recall: 0.9988 - precision: 0.9993 - auc: 0.9997 - val_loss: 0.0682 - val_accuracy: 0.9860 - val_recall: 0.9719 - val_precision: 1.0000 - val_auc: 0.9999\n",
      "Epoch 20/100\n",
      "800/800 [==============================] - 208s 260ms/step - loss: 0.0152 - accuracy: 0.9960 - recall: 0.9943 - precision: 0.9978 - auc: 0.9995 - val_loss: 0.0059 - val_accuracy: 0.9970 - val_recall: 0.9960 - val_precision: 0.9980 - val_auc: 1.0000\n",
      "Epoch 21/100\n",
      "800/800 [==============================] - 208s 260ms/step - loss: 0.0238 - accuracy: 0.9953 - recall: 0.9938 - precision: 0.9970 - auc: 0.9989 - val_loss: 0.0113 - val_accuracy: 0.9960 - val_recall: 0.9940 - val_precision: 0.9980 - val_auc: 0.9999\n",
      "Epoch 22/100\n",
      "800/800 [==============================] - 207s 258ms/step - loss: 0.0134 - accuracy: 0.9975 - recall: 0.9983 - precision: 0.9966 - auc: 0.9992 - val_loss: 0.0126 - val_accuracy: 0.9960 - val_recall: 0.9940 - val_precision: 0.9980 - val_auc: 0.9999\n",
      "Epoch 23/100\n",
      "800/800 [==============================] - 208s 259ms/step - loss: 0.0070 - accuracy: 0.9976 - recall: 0.9975 - precision: 0.9978 - auc: 1.0000 - val_loss: 0.0020 - val_accuracy: 1.0000 - val_recall: 1.0000 - val_precision: 1.0000 - val_auc: 1.0000\n",
      "Epoch 24/100\n",
      "800/800 [==============================] - 205s 256ms/step - loss: 0.0085 - accuracy: 0.9982 - recall: 0.9991 - precision: 0.9973 - auc: 0.9996 - val_loss: 0.0028 - val_accuracy: 0.9990 - val_recall: 0.9980 - val_precision: 1.0000 - val_auc: 1.0000\n",
      "Epoch 25/100\n",
      "800/800 [==============================] - 206s 257ms/step - loss: 0.0136 - accuracy: 0.9964 - recall: 0.9967 - precision: 0.9961 - auc: 0.9992 - val_loss: 0.0198 - val_accuracy: 0.9930 - val_recall: 0.9860 - val_precision: 1.0000 - val_auc: 0.9990\n",
      "Epoch 26/100\n",
      "800/800 [==============================] - 208s 259ms/step - loss: 0.0075 - accuracy: 0.9982 - recall: 0.9978 - precision: 0.9986 - auc: 0.9997 - val_loss: 0.0386 - val_accuracy: 0.9920 - val_recall: 0.9840 - val_precision: 1.0000 - val_auc: 0.9970\n",
      "Epoch 27/100\n",
      "800/800 [==============================] - 207s 258ms/step - loss: 0.0104 - accuracy: 0.9972 - recall: 0.9963 - precision: 0.9981 - auc: 0.9994 - val_loss: 0.0011 - val_accuracy: 1.0000 - val_recall: 1.0000 - val_precision: 1.0000 - val_auc: 1.0000\n",
      "Epoch 28/100\n",
      "800/800 [==============================] - 207s 259ms/step - loss: 0.0043 - accuracy: 0.9991 - recall: 0.9992 - precision: 0.9989 - auc: 0.9998 - val_loss: 0.0223 - val_accuracy: 0.9950 - val_recall: 0.9900 - val_precision: 1.0000 - val_auc: 0.9980\n",
      "Epoch 29/100\n",
      "800/800 [==============================] - 207s 258ms/step - loss: 0.0128 - accuracy: 0.9974 - recall: 0.9982 - precision: 0.9966 - auc: 0.9994 - val_loss: 0.0051 - val_accuracy: 0.9980 - val_recall: 0.9960 - val_precision: 1.0000 - val_auc: 1.0000\n",
      "Epoch 30/100\n",
      "800/800 [==============================] - 207s 258ms/step - loss: 0.0042 - accuracy: 0.9990 - recall: 0.9991 - precision: 0.9989 - auc: 0.9999 - val_loss: 0.0023 - val_accuracy: 0.9990 - val_recall: 0.9980 - val_precision: 1.0000 - val_auc: 1.0000\n",
      "Epoch 31/100\n",
      "800/800 [==============================] - 207s 258ms/step - loss: 0.0047 - accuracy: 0.9985 - recall: 0.9987 - precision: 0.9982 - auc: 0.9999 - val_loss: 5.9797e-04 - val_accuracy: 1.0000 - val_recall: 1.0000 - val_precision: 1.0000 - val_auc: 1.0000\n",
      "Epoch 32/100\n",
      "800/800 [==============================] - 207s 259ms/step - loss: 0.0150 - accuracy: 0.9972 - recall: 0.9985 - precision: 0.9959 - auc: 0.9989 - val_loss: 0.0049 - val_accuracy: 0.9990 - val_recall: 0.9980 - val_precision: 1.0000 - val_auc: 1.0000\n",
      "Epoch 33/100\n",
      "800/800 [==============================] - 201s 251ms/step - loss: 0.0051 - accuracy: 0.9982 - recall: 0.9976 - precision: 0.9988 - auc: 0.9999 - val_loss: 0.0043 - val_accuracy: 0.9990 - val_recall: 0.9980 - val_precision: 1.0000 - val_auc: 1.0000\n",
      "Epoch 34/100\n",
      "800/800 [==============================] - 201s 252ms/step - loss: 0.0087 - accuracy: 0.9977 - recall: 0.9978 - precision: 0.9976 - auc: 0.9996 - val_loss: 0.0255 - val_accuracy: 0.9950 - val_recall: 0.9920 - val_precision: 0.9980 - val_auc: 0.9979\n",
      "Epoch 35/100\n",
      "800/800 [==============================] - 204s 255ms/step - loss: 0.0062 - accuracy: 0.9979 - recall: 0.9984 - precision: 0.9975 - auc: 0.9998 - val_loss: 0.0011 - val_accuracy: 1.0000 - val_recall: 1.0000 - val_precision: 1.0000 - val_auc: 1.0000\n",
      "Epoch 36/100\n",
      "800/800 [==============================] - 204s 255ms/step - loss: 0.0024 - accuracy: 0.9988 - recall: 0.9986 - precision: 0.9991 - auc: 1.0000 - val_loss: 0.0333 - val_accuracy: 0.9860 - val_recall: 0.9719 - val_precision: 1.0000 - val_auc: 1.0000\n",
      "Epoch 37/100\n",
      "800/800 [==============================] - 204s 255ms/step - loss: 0.0146 - accuracy: 0.9968 - recall: 0.9969 - precision: 0.9966 - auc: 0.9993 - val_loss: 0.0031 - val_accuracy: 0.9970 - val_recall: 0.9960 - val_precision: 0.9980 - val_auc: 1.0000\n",
      "Epoch 38/100\n",
      "800/800 [==============================] - 205s 256ms/step - loss: 0.0043 - accuracy: 0.9985 - recall: 0.9983 - precision: 0.9987 - auc: 0.9998 - val_loss: 0.0050 - val_accuracy: 0.9980 - val_recall: 0.9960 - val_precision: 1.0000 - val_auc: 1.0000\n"
     ]
    }
   ],
   "source": [
    "model = compile_model(model, 0.0001, 0.9, 0.999, ['accuracy', 'Recall', 'Precision', 'AUC'])\n",
    "history = train_model(model, train_image_gen, valid_image_gen, 100,\n",
    "                      [custom_early_stopping, tensorboard_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation of the model on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/101 [============================>.] - ETA: 0s - loss: 0.0058 - accuracy: 0.9990 - recall: 0.9980 - precision: 1.0000 - auc: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-07 22:26:28.850816: W tensorflow/core/common_runtime/bfc_allocator.cc:248] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.40GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101/101 [==============================] - 12s 122ms/step - loss: 0.0058 - accuracy: 0.9990 - recall: 0.9980 - precision: 1.0000 - auc: 1.0000\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy, recall, precision, auc = model.evaluate(test_image_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.00580719206482172, \n",
      "accuracy: 0.9990010261535645, \n",
      "recall: 0.9980040192604065, \n",
      "precision: 1.0, \n",
      "auc: 0.9999960064888, \n",
      "F1: 0.9990010126504488\n"
     ]
    }
   ],
   "source": [
    "# F1 score\n",
    "f1 = 2 * ((precision * recall) / (precision + recall))\n",
    "\n",
    "print(f\"loss: {loss}, \\n\"\n",
    "      f\"accuracy: {accuracy}, \\n\"\n",
    "      f\"recall: {recall}, \\n\"\n",
    "      f\"precision: {precision}, \\n\"\n",
    "      f\"auc: {auc}, \\n\"\n",
    "      f\"F1: {f1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving the model to use it for predictions, heatmaps, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "save_model(model, 'xception_heavily_reduced_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyCharm (Quality Control of SLS manufacturing using Convolutional Neural Networks -implementation)",
   "language": "python",
   "name": "pycharm-8f8e9c42"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}